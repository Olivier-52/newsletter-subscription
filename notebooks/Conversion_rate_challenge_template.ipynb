{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\" alt=\"DSW LOGO\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eiKSLYG8XvO"
   },
   "source": [
    "# Challenge : predict conversions üèÜüèÜ\n",
    "\n",
    "This is the template that shows the different steps of the challenge. In this notebook, all the training/predictions steps are implemented for a very basic model (logistic regression with only one variable). Please use this template and feel free to change the preprocessing/training steps to get the model with the best f1-score ! May the force be with you üß®üß®  \n",
    "\n",
    "**For a detailed description of this project, please refer to *02-Conversion_rate_challenge.ipynb*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGhdl7Bt2xZd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, TunedThresholdClassifierCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score , confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHgro65rxKF7"
   },
   "source": [
    "# Read file with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W1AU8AH8u0qd",
    "outputId": "00698a97-027b-493b-a2e4-33fdcc295abb"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XwjKBc63B1n"
   },
   "source": [
    "# Dataset Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.info()\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_perc_df = (data.value_counts('converted')/data.shape[0]).round(2)\n",
    "converted_perc_df.index = ['Not converted','Converted']\n",
    "converted_perc_df.rename('percentage', inplace=True)\n",
    "px.pie(converted_perc_df, values='percentage', names=converted_perc_df.index, title='Conversion rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(converted_perc_df, x=converted_perc_df.index, y=converted_perc_df.values, color=converted_perc_df.index)\n",
    "fig.update_layout(yaxis_title='Visitors', xaxis_title='Conversion', title='Conversion distribution')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_converted = data.groupby('age')['converted'].mean().sort_values(ascending=False)\n",
    "fig = px.bar(x=age_converted.index, y=age_converted.values)\n",
    "fig.update_layout(yaxis_title='Conversion rate', xaxis_title='Age', title='Conversion rate by age')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_converted = data[data['age'] < 62].groupby('age')['converted'].mean().sort_values(ascending=False)\n",
    "fig = px.bar(x=age_converted.index, y=age_converted.values)\n",
    "fig.update_layout(yaxis_title='Conversion rate', xaxis_title='Age', title='Conversion rate by age restricted to < 62')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_visit = data[data['age'] < 62].groupby('age')['total_pages_visited'].mean().sort_values(ascending=False)\n",
    "fig = px.bar(x=age_visit.index, y=age_visit.values)\n",
    "fig.update_layout(yaxis_title='Pages visited', xaxis_title='Age', title='Pages visited by age')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data[data['age'] < 62], x='age', nbins=45)\n",
    "fig.update_layout(yaxis_title='Visitors', xaxis_title='Age', title='Age distribution')\n",
    "fig.update_layout(xaxis=dict(tickvals=list(range(17, 62)),tickmode='array'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x='total_pages_visited', nbins=30)\n",
    "fig.update_layout(yaxis_title='Visitors', xaxis_title='Pages visited', title='Pages visited distribution')\n",
    "fig.update_layout(xaxis=dict(tickvals=list(range(1, 30)),tickmode='array'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_visited_converted = data.groupby('total_pages_visited')['converted'].mean().sort_values(ascending=False)\n",
    "fig = px.bar(x=page_visited_converted.index, y=page_visited_converted.values)\n",
    "fig.update_layout(yaxis_title='Conversion rate', xaxis_title='Pages visited', title='Conversion rate by pages visited')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_converted = data.groupby('new_user')['converted'].mean().sort_values(ascending=False)\n",
    "new_user_converted.index = ['Old user', 'New user']\n",
    "fig = px.bar(x=new_user_converted.index, y=new_user_converted.values, color=new_user_converted.index)\n",
    "fig.update_layout(yaxis_title='Conversion rate', xaxis_title='New user', title='Conversion rate by new user')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x='source', color='source')\n",
    "fig.update_layout(yaxis_title='Visitors', xaxis_title='Source', title='Source distribution')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_converted = data.groupby('source')['converted'].mean().sort_values(ascending=False).round(2)\n",
    "fig = px.bar(x=source_converted.index, y=source_converted.values, color=source_converted.index)\n",
    "fig.update_layout(yaxis_title='Conversion rate', xaxis_title='Source', title='Conversion rate by source')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x='country', color='country')\n",
    "fig.update_layout(yaxis_title='Visitors', xaxis_title='Country', title='Country distribution')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_perc_df = data.groupby('country')['converted'].mean().sort_values(ascending=False).round(2)\n",
    "fig = px.bar(x=converted_perc_df.index, y=converted_perc_df.values, color=converted_perc_df.index)\n",
    "fig.update_layout(yaxis_title='Conversion rate', xaxis_title='Country', title='Conversion rate by country')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70MwsoCS3QD5"
   },
   "source": [
    "# Make your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPh1qPTf3wZU"
   },
   "source": [
    "## Choose variables to use in the model, and create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjEHMGoY3kMB"
   },
   "outputs": [],
   "source": [
    "features_list = ['country', 'age', 'new_user', 'total_pages_visited']\n",
    "target_variable = 'converted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "SV5E9KMs4xcq",
    "outputId": "9d1ed76e-e82e-45e7-f3e5-6d47962caa5a"
   },
   "outputs": [],
   "source": [
    "X = data.loc[:, features_list]\n",
    "Y = data.loc[:, target_variable]\n",
    "print('Explanatory variables : ', X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "W8K5DQEvvQgl",
    "outputId": "d280ebc9-4d4b-4723-b9fe-32513f898abc"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7b_aU7ij7K3Q"
   },
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "_9bEZ5bn7I5Z",
    "outputId": "ad5c8f97-2d25-4827-f1ee-43c665a97fa0"
   },
   "outputs": [],
   "source": [
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "categorical_encoder = OneHotEncoder()\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('encoder', categorical_encoder)\n",
    "])\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_encoder = StandardScaler()\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('encoder', numerical_encoder)\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"numerical\", numerical_pipeline, numerical_features),\n",
    "    (\"categorical\", categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "X_train = preprocessing.fit_transform(X_train)\n",
    "X_test = preprocessing.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = {\n",
    "    'LogisticRegression' : LogisticRegression(random_state=42),\n",
    "    'DecisionTreeClassifier' : DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForestClassifier' : RandomForestClassifier(random_state=42, verbose=0),\n",
    "    'KNeighborsClassifier' : KNeighborsClassifier(),\n",
    "    'XGBClassifier' : XGBClassifier(random_state=42),\n",
    "    'LGBMClassifier' : LGBMClassifier(random_state=42, verbose=0),\n",
    "    'CatBoostClassifier' : CatBoostClassifier(random_state=42, verbose=0, train_dir=r'..\\models'),\n",
    "}\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    print(f'Training {name}...')\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    models.append({'model': f\"{name}\",\n",
    "                   'optimizer': 'Baseline', \n",
    "                   'f1': f1_score(Y_test, Y_pred), \n",
    "                   'precision': precision_score(Y_test, Y_pred), \n",
    "                   'recall': recall_score(Y_test, Y_pred), \n",
    "                   'parameters': model.get_params()})\n",
    "    \n",
    "    print(f\"For baseline {name} model :\")\n",
    "    print(f\"F1-score : {f1_score(Y_test, Y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot = px.bar(pd.DataFrame(models).sort_values('f1', ascending=False), x='model', y='f1', color='model')\n",
    "barplot.update_layout(yaxis_title='f1', xaxis_title='', yaxis_range=[0.70, 0.78], title='Baseline f1 score by model')\n",
    "barplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [100, 200, 500],\n",
    "}\n",
    "\n",
    "dtc_model = LogisticRegression(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(dtc_model, dtc_grid, cv=kf, scoring={'f1': 'f1', 'precision': 'precision', 'recall': 'recall'}, refit='f1', n_jobs=-1)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'LogisticRegression',\n",
    "               'optimizer': 'RandomizedSearchCV', \n",
    "               'f1': random_search.best_score_,\n",
    "               'precision': random_search.cv_results_['mean_test_precision'][random_search.best_index_],\n",
    "               'recall': random_search.cv_results_['mean_test_recall'][random_search.best_index_],\n",
    "               'parameters': random_search.best_params_})\n",
    "\n",
    "print(\"model LogisticRegression\")\n",
    "print(f\"best score : {random_search.best_score_}\")\n",
    "print(\"\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_tuning(trial):\n",
    "\n",
    "  param_grid = {\n",
    "      'penalty': 'l2',\n",
    "      'C': trial.suggest_float('C', 0.001, 100),\n",
    "      'solver': 'lbfgs',\n",
    "      'max_iter': trial.suggest_int('max_iter', 100, 500),\n",
    "      'random_state': 42,\n",
    "    }\n",
    "  \n",
    "  model = LogisticRegression(**param_grid, verbose=0)\n",
    "\n",
    "  model.fit(X_train, Y_train)\n",
    "\n",
    "  return model.score(X_test, Y_test)\n",
    "\n",
    "LogisticRegression_study = optuna.create_study(direction='maximize')\n",
    "LogisticRegression_study.optimize(LogisticRegression_tuning, n_trials=50, n_jobs=-1, timeout=600)\n",
    "\n",
    "model = LogisticRegression(**LogisticRegression_study.best_params, verbose=0)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'LogisticRegression',\n",
    "               'optimizer': 'Optuna', \n",
    "               'f1': f1_score(Y_test, model.predict(X_test)),\n",
    "               'precision': precision_score(Y_test, model.predict(X_test)),\n",
    "               'recall': recall_score(Y_test, model.predict(X_test)),\n",
    "               'parameters': model.get_params()})\n",
    "\n",
    "print(\"model LogisticRegression\")\n",
    "print(f\"best score : {f1_score(Y_test, model.predict(X_test))}\")\n",
    "print(\"\")\n",
    "for param, value in LogisticRegression_study.best_trial.params.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_grid = {\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "\n",
    "dtc_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(dtc_model, dtc_grid, cv=kf, scoring={'f1': 'f1', 'precision': 'precision', 'recall': 'recall'}, refit='f1', n_jobs=-1)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'DecisionTreeClassifier',\n",
    "               'optimizer': 'RandomizedSearchCV', \n",
    "               'f1': random_search.best_score_,\n",
    "               'precision': random_search.cv_results_['mean_test_precision'][random_search.best_index_],\n",
    "               'recall': random_search.cv_results_['mean_test_recall'][random_search.best_index_],\n",
    "               'parameters': random_search.best_params_})\n",
    "\n",
    "print(\"model DecisionTreeClassifier\")\n",
    "print(f\"best score : {random_search.best_score_}\")\n",
    "print(\"\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreeClassifier_tuning(trial):\n",
    "\n",
    "  param_grid = {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'splitter': trial.suggest_categorical('splitter', ['best', 'random']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 500),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 200),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 200),\n",
    "        'random_state': 42,\n",
    "    }\n",
    "  \n",
    "  model = DecisionTreeClassifier(**param_grid)\n",
    "\n",
    "  model.fit(X_train, Y_train)\n",
    "\n",
    "  return model.score(X_test, Y_test)\n",
    "\n",
    "DecisionTreeClassifier_study = optuna.create_study(direction='maximize')\n",
    "DecisionTreeClassifier_study.optimize(DecisionTreeClassifier_tuning, n_trials=50, n_jobs=-1, timeout=600)\n",
    "\n",
    "model = DecisionTreeClassifier(**DecisionTreeClassifier_study.best_params)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'DecisionTreeClassifier',\n",
    "               'optimizer': 'Optuna',\n",
    "               'f1': f1_score(Y_test, model.predict(X_test)),\n",
    "               'precision': precision_score(Y_test, model.predict(X_test)),\n",
    "               'recall': recall_score(Y_test, model.predict(X_test)),\n",
    "               'parameters': model.get_params()})\n",
    "\n",
    "print(\"model DecisionTreeClassifier\")\n",
    "print(f\"best score : {f1_score(Y_test, model.predict(X_test), zero_division=0)}\")\n",
    "print(\"\")\n",
    "for param, value in DecisionTreeClassifier_study.best_trial.params.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = {\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'n_estimators': [10, 50, 100, 200, 300],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0], \n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_model, xgb_grid, cv=kf, scoring={'f1': 'f1', 'precision': 'precision', 'recall': 'recall'}, refit='f1', n_jobs=-1)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'XGBClassifier',\n",
    "               'optimizer': 'RandomizedSearchCV', \n",
    "               'f1': random_search.best_score_,\n",
    "               'precision': random_search.cv_results_['mean_test_precision'][random_search.best_index_],\n",
    "               'recall': random_search.cv_results_['mean_test_recall'][random_search.best_index_],\n",
    "               'parameters': random_search.best_params_})\n",
    "\n",
    "print(\"model XGBClassifier\")\n",
    "print(f\"best score : {random_search.best_score_}\")\n",
    "print(\"\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBClassifier_tuning(trial):\n",
    "\n",
    "  param_grid = {\n",
    "      'subsample': trial.suggest_float('subsample', 0, 1.0),\n",
    "      'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "      'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "      'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "      'max_depth': trial.suggest_int('max_depth', 1, 100),\n",
    "      'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n",
    "      'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "      'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0), \n",
    "      'random_state': 42,\n",
    "    }\n",
    "  \n",
    "  model = XGBClassifier(**param_grid)\n",
    "\n",
    "  model.fit(X_train, Y_train)\n",
    "\n",
    "  return model.score(X_test, Y_test)\n",
    "\n",
    "XGBClassifier_study = optuna.create_study(direction='maximize')\n",
    "XGBClassifier_study.optimize(XGBClassifier_tuning, n_trials=50, n_jobs=-1, timeout=600)\n",
    "\n",
    "model = XGBClassifier(**XGBClassifier_study.best_params)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'XGBClassifier', \n",
    "               'optimizer': 'Optuna',\n",
    "               'f1': f1_score(Y_test, model.predict(X_test)),\n",
    "               'precision': precision_score(Y_test, model.predict(X_test)),\n",
    "               'recall': recall_score(Y_test, model.predict(X_test)),\n",
    "               'parameters': model.get_params()})\n",
    "\n",
    "print(\"model XGBClassifier\")\n",
    "print(f\"best score : {f1_score(Y_test, model.predict(X_test))}\")\n",
    "print(\"\")\n",
    "for param, value in XGBClassifier_study.best_trial.params.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_grid = {\n",
    "    'random_strength': [0.1, 1, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'iterations': [100, 200, 300],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'border_count': [32, 64, 128],\n",
    "    'bagging_temperature': [0, 0.5, 1],\n",
    "}\n",
    "\n",
    "cb_model = CatBoostClassifier(random_state=42, verbose=0, train_dir=r'..\\models')\n",
    "\n",
    "random_search = RandomizedSearchCV(cb_model, cb_grid, cv=kf, scoring={'f1': 'f1', 'precision': 'precision', 'recall': 'recall'}, refit='f1', n_jobs=-1)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'CatBoostClassifier',\n",
    "               'optimizer': 'RandomizedSearchCV', \n",
    "               'f1': random_search.best_score_,\n",
    "               'precision': random_search.cv_results_['mean_test_precision'][random_search.best_index_],\n",
    "               'recall': random_search.cv_results_['mean_test_recall'][random_search.best_index_],\n",
    "               'parameters': random_search.best_params_})\n",
    "\n",
    "print(\"model CatBoostClassifier\")\n",
    "print(f\"best score : {random_search.best_score_}\")\n",
    "print(\"\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CatBoostClassifier_tuning(trial):\n",
    "\n",
    "  param_grid = {\n",
    "      'random_strength': trial.suggest_float('random_strength', 0.1, 10),\n",
    "      'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n",
    "      'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 9),\n",
    "      'iterations': trial.suggest_int('iterations', 10, 500),\n",
    "      'depth': trial.suggest_int('depth', 1, 16),\n",
    "      'border_count': trial.suggest_int('border_count', 32, 128),\n",
    "      'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "    }\n",
    "  \n",
    "  model = CatBoostClassifier(**param_grid, verbose=0, train_dir=r'..\\models')\n",
    "\n",
    "  model.fit(X_train, Y_train)\n",
    "\n",
    "  return model.score(X_test, Y_test)\n",
    "\n",
    "CatBoostClassifier_study = optuna.create_study(direction='maximize')\n",
    "CatBoostClassifier_study.optimize(CatBoostClassifier_tuning, n_trials=50, n_jobs=-1, timeout=600)\n",
    "\n",
    "model = CatBoostClassifier(**CatBoostClassifier_study.best_params, verbose=0, train_dir=r'..\\models')\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'CatBoostClassifier', \n",
    "               'optimizer': 'Optuna',\n",
    "               'f1': f1_score(Y_test, model.predict(X_test)),\n",
    "               'precision': precision_score(Y_test, model.predict(X_test)),\n",
    "               'recall': recall_score(Y_test, model.predict(X_test)),\n",
    "               'parameters': model.get_params()})\n",
    "\n",
    "print(\"model CatBoostClassifier\")\n",
    "print(f\"best score : {f1_score(Y_test, model.predict(X_test))}\")\n",
    "print(\"\")\n",
    "for param, value in CatBoostClassifier_study.best_trial.params.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_grid = {\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'reg_lambda': [0, 0.1, 1],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'num_leaves': [10, 20, 30, 50, 100],\n",
    "    'n_estimators': [10, 50, 100, 200, 300],\n",
    "    'min_child_samples': [20, 50, 100],\n",
    "    'max_depth': [-1, 5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "lgb_model = LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "random_search = RandomizedSearchCV(lgb_model, lgb_grid, cv=kf, scoring={'f1': 'f1', 'precision': 'precision', 'recall': 'recall'}, refit='f1', n_jobs=-1)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'LGBMClassifier',\n",
    "               'optimizer': 'RandomizedSearchCV', \n",
    "               'f1': random_search.best_score_,\n",
    "               'precision': random_search.cv_results_['mean_test_precision'][random_search.best_index_],\n",
    "               'recall': random_search.cv_results_['mean_test_recall'][random_search.best_index_],\n",
    "               'parameters': random_search.best_params_})\n",
    "\n",
    "print(\"model LGBMClassifier\")\n",
    "print(f\"best score : {random_search.best_score_}\")\n",
    "print(\"\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LGBMClassifier_tuning(trial):\n",
    "\n",
    "  param_grid = {\n",
    "      'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
    "      'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "      'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "      'num_leaves': trial.suggest_int('num_leaves', 10, 200),\n",
    "      'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "      'min_child_samples': trial.suggest_int('min_child_samples', 10, 200),\n",
    "      'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
    "      'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n",
    "      'colsample_bytree': trial.suggest_float('colsample_bytree', 0.8, 1.0),\n",
    "      'random_state': 42,\n",
    "    }\n",
    "  \n",
    "  model = LGBMClassifier(**param_grid, verbose=0)\n",
    "\n",
    "  model.fit(X_train, Y_train)\n",
    "\n",
    "  return model.score(X_test, Y_test)\n",
    "\n",
    "LGBMClassifier_study = optuna.create_study(direction='maximize')\n",
    "LGBMClassifier_study.optimize(LGBMClassifier_tuning, n_trials=50, n_jobs=-1, timeout=600)\n",
    "\n",
    "model = LGBMClassifier(**LGBMClassifier_study.best_params, verbose=0)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'LGBMClassifier', \n",
    "               'optimizer': 'Optuna',\n",
    "               'f1': f1_score(Y_test, model.predict(X_test)),\n",
    "               'precision': precision_score(Y_test, model.predict(X_test)),\n",
    "               'recall': recall_score(Y_test, model.predict(X_test)),\n",
    "               'parameters': model.get_params()})\n",
    "\n",
    "print(\"model LGBMClassifier\")\n",
    "print(f\"best score : {f1_score(Y_test, model.predict(X_test))}\")\n",
    "print(\"\")\n",
    "for param, value in LGBMClassifier_study.best_trial.params.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200, 300],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "rfc_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(rfc_model, rfc_grid, cv=kf, scoring={'f1': 'f1', 'precision': 'precision', 'recall': 'recall'}, refit='f1', n_jobs=-1)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'RandomForestClassifier',\n",
    "               'optimizer': 'RandomizedSearchCV', \n",
    "               'f1': random_search.best_score_,\n",
    "               'precision': random_search.cv_results_['mean_test_precision'][random_search.best_index_],\n",
    "               'recall': random_search.cv_results_['mean_test_recall'][random_search.best_index_],\n",
    "               'parameters': random_search.best_params_})\n",
    "\n",
    "print(\"model RandomForestClassifier\")\n",
    "print(f\"best score : {random_search.best_score_}\")\n",
    "print(\"\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestClassifier_tuning(trial):\n",
    "\n",
    "  param_grid = {\n",
    "      'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "      'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "      'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "      'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "      'max_depth': trial.suggest_int('max_depth', 1, 500),\n",
    "      'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),   \n",
    "      'random_state': 42,\n",
    "    }\n",
    "  \n",
    "  model = RandomForestClassifier(**param_grid)\n",
    "\n",
    "  model.fit(X_train, Y_train)\n",
    "\n",
    "  return model.score(X_test, Y_test)\n",
    "\n",
    "RandomForestClassifier_study = optuna.create_study(direction='maximize')\n",
    "RandomForestClassifier_study.optimize(RandomForestClassifier_tuning, n_trials=50, n_jobs=-1)\n",
    "\n",
    "model = RandomForestClassifier(**RandomForestClassifier_study.best_params)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'RandomForestClassifier ', \n",
    "               'optimizer': 'Optuna',\n",
    "               'f1': f1_score(Y_test, model.predict(X_test)),\n",
    "               'precision': precision_score(Y_test, model.predict(X_test)),\n",
    "               'recall': recall_score(Y_test, model.predict(X_test)),\n",
    "               'parameters': model.get_params()})\n",
    "\n",
    "print(\"model RandomForestClassifier\")\n",
    "print(f\"best score : {f1_score(Y_test, model.predict(X_test))}\")\n",
    "print(\"\")\n",
    "for param, value in RandomForestClassifier_study.best_trial.params.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = {\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'n_neighbors': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan', 'chebyshev'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50],\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(knn_model, knn_grid, cv=kf, scoring={'f1': 'f1', 'precision': 'precision', 'recall': 'recall'}, refit='f1', n_jobs=-1)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'KNeighborsClassifier',\n",
    "               'optimizer': 'RandomizedSearchCV', \n",
    "               'f1': random_search.best_score_,\n",
    "               'precision': random_search.cv_results_['mean_test_precision'][random_search.best_index_],\n",
    "               'recall': random_search.cv_results_['mean_test_recall'][random_search.best_index_],\n",
    "               'parameters': random_search.best_params_})\n",
    "\n",
    "print(\"model KNeighborsClassifier\")\n",
    "print(f\"best score : {random_search.best_score_}\")\n",
    "print(\"\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNeighborsClassifier_tuning(trial):\n",
    "\n",
    "  param_grid = {\n",
    "      'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "      'p': trial.suggest_int('p', 1, 2),\n",
    "      'n_neighbors': trial.suggest_int('n_neighbors', 1, 20),\n",
    "      'metric': trial.suggest_categorical('metric', ['minkowski', 'euclidean', 'manhattan', 'chebyshev']),\n",
    "      'leaf_size': trial.suggest_int('leaf_size', 1, 50),\n",
    "      'n_jobs': -1,\n",
    "    }\n",
    "  \n",
    "  model = KNeighborsClassifier(**param_grid)\n",
    "\n",
    "  model.fit(X_train, Y_train)\n",
    "\n",
    "  return model.score(X_test, Y_test)\n",
    "\n",
    "KNeighborsClassifier_study = optuna.create_study(direction='maximize')\n",
    "KNeighborsClassifier_study.optimize(KNeighborsClassifier_tuning, n_trials=50, n_jobs=-1, timeout=600)\n",
    "\n",
    "model = KNeighborsClassifier(**KNeighborsClassifier_study.best_params)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "models.append({'model': 'KNeighborsClassifier', \n",
    "               'optimizer': 'Optuna',\n",
    "               'f1': f1_score(Y_test, model.predict(X_test)),\n",
    "               'precision': precision_score(Y_test, model.predict(X_test)),\n",
    "               'recall': recall_score(Y_test, model.predict(X_test)),\n",
    "               'parameters': model.get_params()})\n",
    "\n",
    "print(\"model KNeighborsClassifier\")\n",
    "print(f\"best score : {f1_score(Y_test, model.predict(X_test))}\")\n",
    "print(\"\")\n",
    "for param, value in KNeighborsClassifier_study.best_trial.params.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame(models)\n",
    "models_df.sort_values(by=['f1', 'precision', 'recall'], ascending=False, inplace=True)\n",
    "print(\"Best model : \", models_df.iloc[0]['model'])\n",
    "print(\"Parameters : \", models_df.iloc[0]['parameters'])\n",
    "display(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "1qhidLbq7o-5",
    "outputId": "6bfb746c-1ff4-41c9-b0d6-a98fd09a444d"
   },
   "outputs": [],
   "source": [
    "# Set model automaticly\n",
    "\n",
    "params = models_df.iloc[0]['parameters']\n",
    "\n",
    "choosen_model = models_df.iloc[0]['model']\n",
    "\n",
    "if choosen_model == \"LogisticRegression\":\n",
    "    model = LogisticRegression(**params)\n",
    "\n",
    "elif choosen_model == \"RandomForestClassifier\":\n",
    "    model = RandomForestClassifier(**params)\n",
    "\n",
    "elif choosen_model == \"DecisionTreeClassifier\":\n",
    "    model = DecisionTreeClassifier(**params)\n",
    "\n",
    "elif choosen_model == \"XGBClassifier\":\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "elif choosen_model == \"LGBMClassifier\":\n",
    "    model = LGBMClassifier(**params)\n",
    "\n",
    "elif choosen_model == \"CatBoostClassifier\":\n",
    "    model = CatBoostClassifier(**params, train_dir=r'..\\models')\n",
    "\n",
    "elif choosen_model == \"SVC\":\n",
    "    model = SVC(**params)\n",
    "\n",
    "elif choosen_model == \"KNeighborsClassifier\":\n",
    "    model = KNeighborsClassifier(**params)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")\n",
    "\n",
    "print(\"Model : \", model.__class__.__name__)\n",
    "print(\"Parameters : \", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/conversion_data_train.csv')\n",
    "data = data[data['age'] < 65]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['country', 'age', 'new_user', 'total_pages_visited']\n",
    "X = data.loc[:, features_list]\n",
    "y = data.loc[:, 'converted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', Pipeline(steps=[('encoder', StandardScaler())]), numerical_features),\n",
    "        ('categorical', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "params =  {'iterations': 187, \n",
    "           'learning_rate': 0.08172004284602592, \n",
    "           'depth': 4, \n",
    "           'l2_leaf_reg': 6, \n",
    "           'border_count': 45, \n",
    "           'verbose': 0, \n",
    "           'random_strength': 7.358305231966604, \n",
    "           'bagging_temperature': 0.2952987331252934}\n",
    "\n",
    "classifier = CatBoostClassifier(**params, train_dir=r'..\\models')\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = TunedThresholdClassifierCV(model, scoring=\"f1\", random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best threshold : {final_model.best_threshold_ :.2f} with f1-score : {final_model.best_score_:.2f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TY_v9uH_CE7"
   },
   "source": [
    "## Final pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxJCTlz0_2it"
   },
   "source": [
    "## Performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6x7p1nyr_3UV",
    "outputId": "8e5b91ba-ca06-4486-d808-37a6aaaa8cf7"
   },
   "outputs": [],
   "source": [
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "y_train_pred = final_model.predict(X_train)\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "print(\"f1-score on train set : \", f1_score(y_train, y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "KhDTCeBy__JK",
    "outputId": "72c82d66-d765-437e-e9ef-4ccc80e7183f"
   },
   "outputs": [],
   "source": [
    "print(\"Confusion matrix on train set : \")\n",
    "test_cm = confusion_matrix(y_train, y_train_pred)\n",
    "fig = px.imshow(test_cm, labels={'x': 'Predicted', 'y': 'Actual'}, text_auto=True)\n",
    "fig.update_layout(xaxis_title='Predicted', yaxis_title='Actual', title='Confusion matrix on train set', width=500, height=500, xaxis=dict(tickvals=list(range(2)),tickmode='array'), yaxis=dict(tickvals=list(range(2)),tickmode='array'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix on test set : \")\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig = px.imshow(test_cm, labels={'x': 'Predicted', 'y': 'Actual'}, text_auto=True)\n",
    "fig.update_layout(xaxis_title='Predicted', yaxis_title='Actual', title='Confusion matrix on test set', width=500, height=500, xaxis=dict(tickvals=list(range(2)),tickmode='array'), yaxis=dict(tickvals=list(range(2)),tickmode='array'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our baseline model reaches a f1-score of almost 70%. Now, feel free to refine your model and try to beat this score ! üöÄüöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tVVDRABv91O"
   },
   "source": [
    "# Train best classifier on all data and use it to make predictions on X_without_labels\n",
    "**Before making predictions on the file conversion_data_test.csv, let's train our model on ALL the data that was in conversion_data_train.csv. Sometimes, this allows to make tiny improvements in the score because we're using more examples to train the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', Pipeline(steps=[('encoder', StandardScaler())]), numerical_features),\n",
    "        ('categorical', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "params =  {'iterations': 187, \n",
    "           'learning_rate': 0.08172004284602592, \n",
    "           'depth': 4, \n",
    "           'l2_leaf_reg': 6, \n",
    "           'border_count': 45, \n",
    "           'verbose': 0, \n",
    "           'random_strength': 7.358305231966604, \n",
    "           'bagging_temperature': 0.2952987331252934}\n",
    "\n",
    "classifier = CatBoostClassifier(**params, train_dir=r'..\\models')\n",
    "\n",
    "base_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "model = TunedThresholdClassifierCV(base_model, scoring=\"f1\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "M14RHUadzE2p",
    "outputId": "abcfcfec-9461-4579-adbd-f23270f984eb"
   },
   "outputs": [],
   "source": [
    "# Concatenate our train and test set to train your best classifier on all data with labels\n",
    "data = pd.read_csv(r'..\\data\\conversion_data_train.csv')\n",
    "X = data.loc[:, features_list]\n",
    "y = data.loc[:, 'converted']\n",
    "\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Tr4CEaPzzbP-",
    "outputId": "f0d1c8ed-be4b-4974-d7b9-f23a49344d9d"
   },
   "outputs": [],
   "source": [
    "# Read data without labels\n",
    "data_without_labels = pd.read_csv('../data/conversion_data_test.csv')\n",
    "print('Prediction set (without labels) :', data_without_labels.shape)\n",
    "\n",
    "# Warning : check consistency of features_list (must be the same than the features \n",
    "# used by your best classifier)\n",
    "X_without_labels = data_without_labels.loc[:, features_list]\n",
    "print('features_list :', features_list)\n",
    "\n",
    "# Convert pandas DataFrames to arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to arrays...\")\n",
    "X_without_labels = X_without_labels.values\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "LoUISfsT0HMR",
    "outputId": "e42dc389-5e77-4e13-ccbc-1fef4aa2c0ca"
   },
   "outputs": [],
   "source": [
    "# WARNING : PUT HERE THE SAME PREPROCESSING AS FOR YOUR TEST SET\n",
    "# CHECK YOU ARE USING X_without_labels\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "X_without_labels = pd.DataFrame(X_without_labels, columns=features_list)\n",
    "predictions = model.predict(X_without_labels)\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DuWSEHuwEQJ"
   },
   "outputs": [],
   "source": [
    "# Make predictions and dump to file\n",
    "# WARNING : MAKE SURE THE FILE IS A CSV WITH ONE COLUMN NAMED 'converted' AND NO INDEX !\n",
    "# WARNING : FILE NAME MUST HAVE FORMAT 'conversion_data_test_predictions_[name].csv'\n",
    "# where [name] is the name of your team/model separated by a '-'\n",
    "# For example : [name] = AURELIE-model1\n",
    "user_name = \"Olivier\"\n",
    "\n",
    "if len(os.listdir('../models/model_predictions')) == 0:\n",
    "    run_number = 1\n",
    "else:\n",
    "    pattern = r'-(\\d{1})\\.csv$'\n",
    "    run_numbers = [int(re.search(pattern, file).group(1)) for file in os.listdir('../models/model_predictions') if re.search(pattern, file)]\n",
    "    run_number = max(run_numbers) + 1\n",
    "\n",
    "name = f\"{user_name}-{model.__class__.__name__}-{run_number}\"\n",
    "\n",
    "data = {\n",
    "    'converted': predictions\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'],data=data)\n",
    "Y_predictions.to_csv(f'../models/model_predictions/conversion_data_test_predictions_{name}.csv', index=False)\n",
    "print(f\"File {f'../models/model_predictions/conversion_data_test_predictions_{name}.csv'} created !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the coefficients and interpreting the result\n",
    "**In this template, we just trained a model with only one feature (total_pages_visited), so there's no analysis to be done about the feature importance ü§î**\n",
    "\n",
    "**Once you've included more features in your model, please take some time to analyze the model's parameters and try to find some lever for action to improve the newsletter's conversion rate üòéüòé**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model name : \", name)\n",
    "print(\"model type : \", model.__class__.__name__)\n",
    "print(\"f1-score on train set : \", f1_score(y_train, y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(y_test, y_test_pred))\n",
    "print(\"parameters : \", model.get_params())\n",
    "\n",
    "models_df = pd.DataFrame({\n",
    "    'model': [model.__class__.__name__],\n",
    "    'optimizer': ['TunedThresholdClassifierCV'],\n",
    "    'f1': [f1_score(y_test, y_test_pred)],\n",
    "    'precision': [precision_score(y_test, y_test_pred)],\n",
    "    'recall': [recall_score(y_test, y_test_pred)],\n",
    "    'parameters': [model.get_params()]\n",
    "})\n",
    "\n",
    "if not os.path.exists('../data/models_summary.csv'):\n",
    "    models_df.to_csv('../data/models_summary.csv', index=False)\n",
    "    print(\"Model summary file created\")\n",
    "\n",
    "else:\n",
    "    models_df.to_csv('../data/models_summary.csv', mode='a', header=False, index=False)\n",
    "    print(\"New models added to models_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_summary = pd.read_csv('../data/models_summary.csv')\n",
    "models_summary.drop_duplicates(inplace=True, ignore_index=True)\n",
    "models_summary.dropna(subset=['f1'], inplace=True)\n",
    "models_summary.sort_values('f1', ascending=False, inplace=True)\n",
    "#models_summary = models_summary[models_summary['f1'] != 0]\n",
    "#models_summary.to_csv('../data/models_summary.csv', index=False)\n",
    "display(models_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores= models_summary.groupby('model')[['f1', 'precision', 'recall']].max().reset_index()\n",
    "models_scores = models_scores.sort_values('f1', ascending=False)\n",
    "fig = px.bar(models_scores, x='model', y=['f1', 'precision', 'recall'], barmode='group', title='Models metrics comparison')\n",
    "fig.update_layout(yaxis_title='Scores', xaxis_title='Models', yaxis_range=[0.65, 0.88])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(models_summary[models_summary['f1'] >0.6], x='f1', color='model').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_scores= models_summary.groupby('optimizer')[['f1', 'precision', 'recall']].max().reset_index()\n",
    "optimizers_scores = optimizers_scores.sort_values('f1', ascending=False)\n",
    "fig = px.bar(optimizers_scores, x='optimizer', y=['f1', 'precision', 'recall'], barmode='group', title='Optimizers metrics comparison')\n",
    "fig.update_layout(yaxis_title='Scores', xaxis_title='Optimizers', yaxis_range=[0.65, 0.88])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot = px.box(models_summary.sort_values('f1', ascending=False), x='optimizer', y='f1', color='optimizer', hover_data=['model'])\n",
    "box_plot.update_layout(yaxis_title='f1', xaxis_title='', title='F1 score distribution by optimizer')\n",
    "box_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot = px.bar(models_summary.sort_values('f1', ascending=False), x='optimizer', y='f1', color='model', barmode='group')\n",
    "bar_plot.update_layout(yaxis_title='f1', xaxis_title='', yaxis_range=[0.72, 0.80], title='Best F1 score by model/optimizer')\n",
    "bar_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot = px.bar(models_summary.sort_values('recall', ascending=False), x='model', y='recall', color='optimizer', barmode='group')\n",
    "bar_plot.update_layout(yaxis_title='recall', xaxis_title='',yaxis_range=[0.60, 0.72],  title='Best recall score by model/optimizer')\n",
    "bar_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot = px.bar(models_summary.sort_values('precision', ascending=False), x='model', y='precision', color='optimizer', barmode='group')\n",
    "bar_plot.update_layout(yaxis_title='precision', xaxis_title='',yaxis_range=[0.80, 0.90],  title='Best precision score by model/optimizer')\n",
    "bar_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model global performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = models_summary[models_summary['optimizer'] == 'Optuna']\n",
    "fig = px.bar()\n",
    "fig.add_bar(x=model_scores['model'], y=model_scores['f1'], name='f1')\n",
    "fig.add_bar(x=model_scores['model'], y=model_scores['precision'], name='precision')\n",
    "fig.add_bar(x=model_scores['model'], y=model_scores['recall'], name='recall')\n",
    "fig.update_layout(yaxis_title='Score', xaxis_title='', title='Model scores with Optuna optimization', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = models_summary[models_summary['optimizer'] == 'Baseline']\n",
    "fig = px.bar()\n",
    "fig.add_bar(x=model_scores['model'], y=model_scores['f1'], name='f1')\n",
    "fig.add_bar(x=model_scores['model'], y=model_scores['precision'], name='precision')\n",
    "fig.add_bar(x=model_scores['model'], y=model_scores['recall'], name='recall')\n",
    "fig.update_layout(yaxis_title='Score', xaxis_title='', title='Baseline model scores', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier_model = models_summary.loc[models_summary['model'] == \"XGBClassifier\"].copy()\n",
    "XGBClassifier_model['parameters'] = XGBClassifier_model['parameters'].apply(lambda x: eval(x))\n",
    "params_df = XGBClassifier_model['parameters'].apply(pd.Series)\n",
    "XGBClassifier_model = pd.concat([XGBClassifier_model.drop('parameters', axis=1), params_df], axis=1)\n",
    "XGBClassifier_model.sort_values('f1', ascending=False, inplace=True)\n",
    "#XGBClassifier_model.drop('verbose', axis=1, inplace=True)\n",
    "display(XGBClassifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression_model = models_summary.loc[models_summary['model'] == \"LogisticRegression\"].copy()\n",
    "LogisticRegression_model['parameters'] = LogisticRegression_model['parameters'].apply(lambda x: eval(x))\n",
    "params_df = LogisticRegression_model['parameters'].apply(pd.Series)\n",
    "LogisticRegression_model = pd.concat([LogisticRegression_model.drop('parameters', axis=1), params_df], axis=1)\n",
    "LogisticRegression_model.sort_values('f1', ascending=False, inplace=True)\n",
    "LogisticRegression_model.drop('verbose', axis=1, inplace=True)\n",
    "display(LogisticRegression_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', Pipeline(steps=[('encoder', StandardScaler())]), numerical_features),\n",
    "        ('categorical', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "params =  {'iterations': 187, \n",
    "           'learning_rate': 0.08172004284602592, \n",
    "           'depth': 4, \n",
    "           'l2_leaf_reg': 6, \n",
    "           'border_count': 45, \n",
    "           'verbose': 0, \n",
    "           'random_strength': 7.358305231966604, \n",
    "           'bagging_temperature': 0.2952987331252934,\n",
    "           }\n",
    "\n",
    "classifier = CatBoostClassifier(**params, train_dir='../models')\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/conversion_data_train.csv')\n",
    "X = data.loc[:, features_list]\n",
    "y = data.loc[:, 'converted']\n",
    "\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, f'../models/{model.__class__.__name__}.joblib')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projets_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
